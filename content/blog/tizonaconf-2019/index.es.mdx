---
banner: 'banners/placeholder.png'
categories: ['Congress']
date: '2019-10-28T12:00:00+01:00'
description: 'Cada vez estoy más acostumbrado a asistir a conferencias en los fines de semana, las que más me gustan es en las que el ambiente da para entablar amistades y se nota en el lugar y en la gente que está más abierta a hablar, echar unas cañas y compartir sus experiencias.'
tags: ['TizonaConf', 'privacy', 'industry', 'security', 'voice assistants']
draft: false
title: '[CON] TizonaConf: Ciberseguridad en entornos industriales'
image: './images/post-image.jpg'
type: 'blog'
---

Cada vez estoy más acostumbrado a asistir a conferencias en los fines de semana, las que más me gustan es en las que el ambiente da para entablar amistades y se nota en el lugar y en la gente que está más abierta a hablar, echar unas cañas y compartir sus experiencias. El pasado 17 y 18 de octubre fui a **TizonaConf**, un nuevo congreso con ese _ambiente_ que he descrito.... y **¡En [Burgos](https://es.wikipedia.org/wiki/Burgos)!** Estoy orgulloso de haber podido formar parte de esta conferencia sobre ciberseguridad en [Castilla y León](https://en.wikipedia.org/wiki/Castile_and_Le%C3%B3n).

![Tizona](/images/tizona.PNG)

**Tizona** a parte una sorpresa inesperada es una conferencia única. No es el típico evento que surge cuando un gran grupo de profesionales decide empezar algo más grande... es lo contrario, Tizona es un evento que busca reunir profesionales de la zona para **crear una comunidad de seguridad**, [burgos4hack](http://www.burgos4hack.com).

Si estas interesado, son un grupo de profesionales, estudiantes, desarrolladores, pentesters... con un foco en la ciberseguridad (aunque sin dejar de lado otros temas de la informática). Puedes **echar un ojo** aquí a su [página web](http://www.burgos4hack.com).

## ¿Sobre qué hablé?

Tizona trata la seguridad en enternos industriales. Siguiendo mis temas habituales, hablé sobre asistentes de voz en este contexto. Ahora mismo, este tipo de dispositivos no están presentes en este entorno pero no es descabellado pensar en un futuro cercano donde la gente use este tipo de interfaces para realizar tareas más complejas en la industria. ¿Lo ves una locura? Trabajo en un laboratorio de ciberseguridad, mi trabajo muchas veces es sacar la bola de cristal y plantear futuros _no muy impredecibles_... esperad a que Google, Amazon, Microsoft o cualquier otro decida empezar a regalar _"Asistentes Industriales"_ a las empresas que gasten más de cierta cantidad en **servicios cloud**, **infrastructura IoT** o **cajas de cereales**.

No sé si lo tomas como una predicción loca, imposible o segura pero estoy seguro de que todos estamos de acuerdo en el hecho de que se necesita lidiar con los **riesgos** y las **responsabilidades** de este tipo de tecnología en enternos industriales.

Ya he hablado en otras ocasiones de **riesgos de privacidad** en el hogar. Como comenté en [JASyP](https://www.croke.es/es/blog/tizonaconf-2019/), estos dispositivos cuentan con una larga lista de riesgos relacionados entre si y que conectan entornos físicos y digitales.

![Risks list](/images/risks.png)

Mirando la lista, podemos imaginar el tipo de problemas que podrían aparecer de estos riegos. Más aun, en entornos industriales donde podemos encontrar nuevos tipos de riesgos a mayores de los de la diapositiva:

### Control por Voz

La característica principal de estos dispositivos también implica que existe el riesgo de un atacante consiguiendo imitar la voz de una persona para **saltarse la autenticación** de los sistemas de control.

Estos dispositivos pueden ser usados por cualquiera con capacidad de hablar al asistente, el altavoz inteligente (al que por concienciación deberíamos llamar micrófono) será el **receptor de los permisos** necesarios para realizar las tareas, por lo que, cualquiera que este a una distancia en que el altavoz le escuche y pueda hablar con él, podrá también realizar esas tareas. Muchos asistentes de voz reconocen la voz del dueño y autorizan al usuario de esta manera, pero no todos cuentan con esta funcionalidad. Además, este tipo de funcionalidad es útil cuando no se habla de autorizar grupos enteros de trabajadores que rotan frecuentemente, porque, el coste en tiempo de configurar la autorización sería sino demasiado alto.

A parte, una atacante paciente podría **grabar la voz** de un usuario autorizado. ¿Por qué? Por ejemplo para realizar un **ataque de _replay_** o para entrenar una red neuronal que imite la voz de la vistima como hace [Lyrebird](https://www.descript.com/lyrebird-ai?source=lyrebird).

### Exfiltración de datos

En este tipo de interfaces tan novedosas los productos de seguridad y las empresas no están aun preparados para monitorizar los datos que se envían mediante estos dispositivos. Algunos pueden crear una **lista blanca** y permitir ejecutar sólo ciertas aplicaciones/_skills_ en el ~~altavoz~~ micrófono pero esto no se establece como una configuración por defecto. Algún día habrá una filtración de datos y nadie se fijará en al configuración del asistente de voz.

## ¿Amenaza ó Ayuda?

Definitivamente.... las dos. Estos dispositivos son sin duda un cambio **rompedor** si hablamos de **UX**. Estas interfaces son un ejemplo de cómo **simplificar tareas complejas** al usuario final. Usar lenguaje natural, evitando el uso de dispositivos físicos, abstrae muchos conceptos difíciles y comunes en el mundo digital. La idea detras de estos dispositivos es impresionante y los casos de uso que enseñan en la publicidad son una pasada: ayudar personas con una discapacidad, traer nuevas tecnologías a personas mayores o ayudar en las tareas diarias usando IoT son algunos ejemplos.

![Incidents](/images/incidents.png)

Las últimas noticias sobre este tema dejan claro que los asistentes son también una **amenaza**. Todas las compañías principales del sector han admitido **filtraciones de datos**, fallos de seguridad en sus _third-party_ y personas que escuchan las conversaciones de otras para "mejorar el servicio". Estos son los **enlaces** de algunos de estos ejemplos.

- Confirmado: Apple pillado en un escandalo de privacidad con **Siri**. [Fuente: Forbes](https://www.forbes.com/sites/jeanbaptiste/2019/07/30/confirmed-apple-caught-in-siri-privacy-scandal-let-contractors-listen-to-private-voice-recordings/#7e497cfe7314)
- **Google** admite que sus _partners_ han filtrado mas de 1000 conversaciones privadas. [Fuente: CNBC](https://www.cnbc.com/2019/07/11/google-admits-leaked-private-voice-conversations.html)
- Amazon reporta que contrató a miles de personas para escuchar las conversaciones de **Alexa**. [Fuente: CNN](https://edition.cnn.com/2019/04/11/tech/amazon-alexa-listening/index.html)

## Algunos hechos sobre los asistentes de voz auditados

Después de estas noticias surgió en el departamento una concienciación sobre los riesgos de los asistentes de voz, esto nos llevo a empezar una investigación sobre este tipo de dispositivos con dos aproximaciones paralelas: Fallos de seguridad en el software y problemas de seguridad en el hardware. Aquí se resume parte de las lecciones que aprendimos de esas auditorías:

- Es posible **esconder dispositivos hardware** dentro de los asistentes, la cámara de aire del altavoz es perfecta para esconder un micrófono y el proceso de desmontarlo lleva entre 10 y 25 minutos, dependiendo del asistente.
- Todos estos dispositivos tienen un **array de micrófonos**, uno o más **altavoces** y una placa base que se usa para reconocer el comando de activación y la configuración del dispositivo.
- Tienen un botón físico para **mutear** el micrófono.
- En algunas plataformas de desarrollo es posible saltarse las medidas de seguridad en el editor para poder desarrollar malware que empieza una **escucha activa ilimitada**[1](https://www.elladodelmal.com/2019/10/un-phishing-con-cognitive-services.html).
- Google Home tiene una **API oculta** que puede accederse desde lar ed local y que permite hacer un DoS permanente al dispositivo.
- Desde mi punto de vista, los asistentes virtuales no están desarrollados al completo y su funcionalidad no es **aún** realmente útil.

## Mitigaciones: Alias

No hay ningún producto comercial que mejore la seguridad de estos dispositivos, pero, si que hay una **prueba de concepto** que he tenido la oportunidad de recrear. Hablo de el **[proyecto Alias](http://bjoernkarmann.dk/project_alias)**, un proyecto hecho por [Bjørn Karmann](http://bjoernkarmann.dk/) y [Tore Knudsen](http://www.toreknudsen.dk/) que funciona como un _"parásito"_ colocado en la parte superior del asistente de voz.

Alias se contruye usando una Raspberry Pi, un array de micrófonos y un par de altavoces. Se entrena para proveer de una palabra de activación personalizada por nosotros mismos usando una aplicación web. Por ejemplo podemos usar _Croke_, una vez entrenado, colocamos Alias en la parte superior del asistente. Los altavoces de Alias debe estar justo encima de los micrófonos del asistente. En ese momento, el dispositivo reproduce de contínuo un ruido blanco que neutraliza la escucha del asistente virtual. Is pronunciamos nuestro comando, _"croke, ¿Qué hora es?"_, Alias coge la primera parte, lo reconoce como su comando de activación y para el ruido que neutraliza los micrófonos del asistente. Esto permite que el asistente escuche el resto del comando de nuestra boca. Por ejemplo:

![Alias](/images/alias.png)

_Croke..._ (Alias para el ruido y reproduce _Ok Google_) _...¿Qué hora es?_ (Google home responde con la hora).

Una vez entendido el proyecto, la idea es **simple** y **asequible**. También es **sencilla** de recrear por nosotros mismos. Sólo es una prueba de concepto y puede usarse en nuestras casas pero no está del todo desarrollada y aun tiene algunos problemas. Es un proyecto muy interesante y **debería ser continuado**.

Si quieres probarlo, hay un tutorial de cómo construirlo en [Instructables](https://www.instructables.com/id/Project-Alias/).

## Las alternativas _open source_: Mycroft

Si hablamos de asistentes virtuales, hay que hablar de **Mycroft**, una alternativa _open source_ preparada para ejecutarse en una Raspberry Pi. Este proyecto cuenta con la colaboración de Mozilla Things, DeepSpeech y KDE. Ofrece varios modelos de hardware especializado llamados Mark I y Mark II. Si quieres empezar un proyecto con asistentes de voz te animo a probar primero Mycroft.

![Mycroft](/images/mycroft.png)

Esta es [la página web oficial](https://mycroft.ai/).

## Conclusión

Las nuevas tecnologías pueden ser herramientas que resuelven nuestros problemas de una nueva forma y más simple, pero, si hablamos sobre trabajos industriales y controles de seguridad no podemos confiar la seguridad en productos no probados y que siguen aun en desarrollo sin funcionalidad específica para entornos profesionales.

## Todo muy bonito pero... ¿Qué tal fue el congreso?

Tengo que agradecer a la organización del congreso, especialmente a [@manuelbocos](https://twitter.com/manuelbocos) por toda la ayuda y la cálida acogida. La organización fue excelente y eso que era solo la primera edición. No puedo esperar a la siguiente TizonaConf.

![Gifts](/images/branding.jpg)

Y no sólo el congreso, fue una gran experiencia conocer a [@TheXXLMAN](https://twitter.com/TheXXLMAN), [@RadioHacking](https://twitter.com/RadioHacking), Carlos Rioja, Paco Montserrat o [@javioreto](https://twitter.com/javioreto). Una buena cerveza no es lo mismo sin buena charla y compañía.

![The beers](/images/tizona.jpg)

## La presentación

Si te interesa la **privacidad** y la **seguridad**, te animo a echarle un ojo a la [**presentación**](https://docs.google.com/presentation/d/1qguUIEktor6wzUed0-gMfRtfOTAUK1QzwtI2StDeZQU/edit?usp=sharing) de la charla.

**Gracias** por leer este artículo. Si tienes alguna **duda**, comentario o simplemente quieres decir un hola... puedes **contactarme** en [Twitter](https://twitter.com/coke727), el formulario de contacto o incluso señales de humo =P

![Thanks](/images/thanks.png)

**No dudes en preguntarme cualquier duda vía Twitter, email o el formulario de la página principal.**
